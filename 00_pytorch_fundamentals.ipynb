{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BMPEtyL1aZby",
        "zqifVxmRaBgi",
        "g9bHTR3jkuDr",
        "VGLJ7mHWr9_2",
        "BhayhfGI03J5",
        "9x-m2P_X7pU9",
        "QROJdy7bD0T-",
        "iPHKgZUXK1KA",
        "FT3gAnDZNi7M",
        "eIwaJfMb9YyP",
        "aSCq3ZqZBBsS",
        "7uayyyXqEmXs",
        "eTWxoO1k0yFp",
        "Y_VYrwjwt_S2",
        "ZQD8bpqOChsw",
        "5dWcE3rWMski",
        "O0K3zfBbwa16",
        "SSpMm-0nwnJK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Resource Link: https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises"
      ],
      "metadata": {
        "id": "fPCWsihGzXzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOSmuwB2LEhj",
        "outputId": "ddcceb5a-bd03-47e2-852e-2e34ba6a6f1c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ESnUlcanGGd3"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Tensors\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FCG5INYwysxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Tensors\n"
      ],
      "metadata": {
        "id": "BMPEtyL1aZby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "PyTorch tensors are created using torch.Tensor() = https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "---\n",
        "\n",
        "* Scalar (Rank 0 Tensor): A scalar is a single number. In PyTorch, you create a scalar by passing a single value to torch.tensor(). The code creates a scalar with a value of 7. .ndim checks the number of dimensions (which is 0 for a scalar), .shape returns an empty tuple since scalars have no dimensions, and .item() converts the tensor scalar to a standard Python scalar.\n",
        "\n",
        "* Vector (Rank 1 Tensor): A vector is a 1-dimensional array of numbers. The code creates a vector [7, 7] using torch.tensor(). Here, .ndim returns 1 indicating it's 1-dimensional, and .shape returns (2), meaning the vector has 2 elements.\n",
        "\n",
        "* Matrix (Rank 2 Tensor): A matrix is a 2-dimensional array of numbers. The example creates a 2x2 matrix with torch.tensor([[7, 8], [9, 10]]). .ndim shows it's 2-dimensional, and .shape returns (2, 2), indicating 2 rows and 2 columns.\n",
        "\n",
        "* Higher-Dimensional Tensor (Rank 3+ Tensor): Tensors can have three or more dimensions. The provided code creates a tensor with dimensions (1, 3, 3), meaning it contains a 3x3 matrix in a 3-dimensional space. .ndim confirms it's 3-dimensional. The shape is described as having 1 matrix that contains 3 rows and 3 columns each.\n",
        "\n",
        "This code is a basic introduction to the concept of tensors in PyTorch, demonstrating how to create them and inspect their properties like dimensionality and shape. Understanding these properties is essential for working with data in machine learning and deep learning applications.\n",
        "\n",
        "---\n",
        "\n",
        "**Naming Conventions**\n",
        "* Scalar (dimension = 0) - lower-case $a$\n",
        "* Vector (dimension = 1) - lower-case $y$\n",
        "* Matrix (dimension = 2) - upper-case $Q$\n",
        "* Tensor (dimension â‰¥ 3) - upper-case $X$"
      ],
      "metadata": {
        "id": "zqifVxmRaBgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar (tensor rank 0)\n",
        "scalar = torch.tensor(7) # A tensor can be constructed from a Python list or sequence using the torch.tensor() constructor\n",
        "\n",
        "print(scalar)\n",
        "print(scalar.ndim) # checks how many dimensions does scalar have\n",
        "print(scalar.shape)\n",
        "print(scalar.item()) # Get tensor back as Python int\n"
      ],
      "metadata": {
        "id": "gD0W48aJy93i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ce9194-1607-483b-ab24-15b574e31468"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7)\n",
            "0\n",
            "torch.Size([])\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The .item() method is specific to tensors that have a single element. Its purpose is to extract the value of that single element as a standard Python number (int or float). It's particularly useful when you're working with tensors that result from some computations, and you want to convert the result into a Python scalar.\n",
        "\n",
        "> Attempting to use .item() on a tensor with more than one element will result in an error because it's not clear which element should be converted to a Python scalar. The method is designed to ensure that it's only used when there's exactly one element in the tensor, thereby avoiding ambiguous situations."
      ],
      "metadata": {
        "id": "0TQh-ehvd9dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector (tensor rank 1)\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector)\n",
        "print(vector.ndim) # checks how many dimension does vector have\n",
        "print(vector.shape) # outputs the shape of the vector, eg 2 by 1."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8dtOEDVW_nd",
        "outputId": "cc92440f-99b9-4d73-b070-061e77b12c77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7, 7])\n",
            "1\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix (tensor rank 2)\n",
        "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
        "print(MATRIX)\n",
        "print(MATRIX.ndim) # checks how many dimension does MATRIX have\n",
        "print(MATRIX.shape) # outputs the shape of the matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT1E57eiYTLz",
        "outputId": "7ef87c4c-29a8-4922-d8c6-93b52ce4c337"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7,  8],\n",
            "        [ 9, 10]])\n",
            "2\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor (tensor rank 3+)\n",
        "TENSOR = torch.tensor([[[1, 2, 3],   #[ <-- dim=0[ <-- dim=1 [ <-- dim=2 ]]]\n",
        "                        [4, 5, 6],\n",
        "                        [6, 7, 8]]])\n",
        "print(TENSOR)\n",
        "print(TENSOR.ndim) # checks how many dimension does TENSOR have\n",
        "\n",
        "print(TENSOR.shape) # outputs the shape of the tensor\n",
        "                    # torch.Size([1, 3, 3]) means that you have 1x 3 by 3 matrix in this tensor.\n",
        "                    # torch.Size([dim=0, dim=1, dim=2])\n",
        "                    # alternatively, dim=0 contains 1 value (matrix), dim=1 contains 3 values (vector), dim=2 contains 3 scalars each.\n"
      ],
      "metadata": {
        "id": "w8NT_D3hW0NI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6612bb70-21e2-4a2e-fe6c-b1fd130debc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [6, 7, 8]]])\n",
            "3\n",
            "torch.Size([1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Tensors\n",
        "\n"
      ],
      "metadata": {
        "id": "g9bHTR3jkuDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why random tensors?**\n",
        "\n",
        "Random tensors are important because the way many neural network learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "Workflow:\n",
        "\n",
        "> `Start with random numbers -> Look at data -> Update random numbers -> Look at data -> Update random numbers`\n",
        "\n",
        "PyTorch Docs (torch.rand()) url - https://pytorch.org/docs/stable/generated/torch.rand.html\n"
      ],
      "metadata": {
        "id": "SXvKoBOIaPKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (4, 3, 4)\n",
        "random_tensor = torch.rand(4, 3, 4) # can write \"touch.rand(size=(4, 3, 4))\" // both are acceptable\n",
        "print(random_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3OAoLvKldT6",
        "outputId": "ec2e4d22-6b35-4a7d-c841-b2caccbc2adf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[3.1819e-01, 6.4301e-01, 3.7265e-01, 8.3622e-01],\n",
            "         [4.6241e-01, 1.2688e-01, 1.1209e-01, 7.0268e-01],\n",
            "         [1.1939e-01, 6.4807e-01, 8.0514e-01, 3.4811e-01]],\n",
            "\n",
            "        [[2.2211e-01, 9.2608e-01, 6.2135e-01, 9.7105e-01],\n",
            "         [3.1338e-01, 9.5852e-01, 8.3803e-01, 6.9827e-02],\n",
            "         [1.1109e-01, 8.6737e-01, 8.6464e-01, 2.2208e-01]],\n",
            "\n",
            "        [[4.3882e-01, 7.0608e-03, 2.1993e-01, 3.3212e-04],\n",
            "         [3.3231e-01, 2.2853e-01, 8.7166e-01, 3.1274e-01],\n",
            "         [7.4625e-01, 7.5750e-01, 6.0879e-01, 1.6560e-01]],\n",
            "\n",
            "        [[4.6921e-01, 6.4979e-01, 7.2260e-01, 5.1278e-01],\n",
            "         [4.5194e-01, 4.7757e-02, 7.1894e-01, 2.0497e-01],\n",
            "         [1.6052e-01, 4.9845e-01, 2.7172e-01, 5.3574e-01]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(random_tensor.ndim) # checks how many dimension does random_tensor have\n",
        "print(random_tensor.shape) # outputs the shape of the random_tensor"
      ],
      "metadata": {
        "id": "pyNw82U6rz-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "addfbad6-3609-4d3c-fc49-11e535b89ab4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "torch.Size([4, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with simillar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # alternative is colour channel coming first, eg. size=(3, 224, 224) // both image dimension of 224x224\n",
        "print(random_image_size_tensor.ndim) # checks dimension of random_image_size_tensor\n",
        "print(random_image_size_tensor.shape) # outputs shape of random_image_size_tensor\n",
        "\n",
        "# random tensors are so valuable because neural network starts with random data -> look at data -> update the random numbers -> look at data ....."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IptIzup9r1zM",
        "outputId": "158d45d1-754e-4f67-bf67-0bed3c3b4e0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "torch.Size([224, 224, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zeros and Ones"
      ],
      "metadata": {
        "id": "VGLJ7mHWr9_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all zeroes\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "print(zeros)\n",
        "print(zeros * random_tensor) # multiply zero tensor with random tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dTV48tbyNit",
        "outputId": "81d02ace-9dcd-4595-b8fe-6ea1f97050a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "print(ones)\n",
        "print(ones * random_tensor) # multiply zero tensor with random tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "596fd376-aef7-4912-967f-1001e4ad16d5",
        "id": "65SLMGmxywbK"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[[3.1819e-01, 6.4301e-01, 3.7265e-01, 8.3622e-01],\n",
            "         [4.6241e-01, 1.2688e-01, 1.1209e-01, 7.0268e-01],\n",
            "         [1.1939e-01, 6.4807e-01, 8.0514e-01, 3.4811e-01]],\n",
            "\n",
            "        [[2.2211e-01, 9.2608e-01, 6.2135e-01, 9.7105e-01],\n",
            "         [3.1338e-01, 9.5852e-01, 8.3803e-01, 6.9827e-02],\n",
            "         [1.1109e-01, 8.6737e-01, 8.6464e-01, 2.2208e-01]],\n",
            "\n",
            "        [[4.3882e-01, 7.0608e-03, 2.1993e-01, 3.3212e-04],\n",
            "         [3.3231e-01, 2.2853e-01, 8.7166e-01, 3.1274e-01],\n",
            "         [7.4625e-01, 7.5750e-01, 6.0879e-01, 1.6560e-01]],\n",
            "\n",
            "        [[4.6921e-01, 6.4979e-01, 7.2260e-01, 5.1278e-01],\n",
            "         [4.5194e-01, 4.7757e-02, 7.1894e-01, 2.0497e-01],\n",
            "         [1.6052e-01, 4.9845e-01, 2.7172e-01, 5.3574e-01]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# datatype\n",
        "print(zeros.dtype)\n",
        "print(ones.dtype)\n",
        "print(random_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTjB927ny7Nc",
        "outputId": "bb2181b6-fd5f-419a-e454-8f4953fd278a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.float32\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Range of Tensors and Tensors-like\n",
        "\n"
      ],
      "metadata": {
        "id": "BhayhfGI03J5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch docs for \"torch.arange()\" - https://pytorch.org/docs/stable/generated/torch.arange.html"
      ],
      "metadata": {
        "id": "jnZPjW9tbLID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.range(0, 10) # depracated method, use \"torch.arange()\" instead\n",
        "one_to_ten = torch.arange(0, 10) # tensor.arange() starts at start_int, ends at end_int - 1.\n",
        "print(one_to_ten)\n",
        "one_to_k = torch.arange(start=0, end=1000, step=77)\n",
        "print(one_to_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K87hTXL-0-8v",
        "outputId": "e7cac6d4-a48c-4c03-eac5-233ad10f0a28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors like\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten) # this will get you a tensor full of zeros, which is the same shape as the tensor input, ie \"one_to_ten\"\n",
        "print(ten_zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSKlSEhj1IE6",
        "outputId": "2d52b8d0-34c5-4430-ff36-1a3bb8e0be88"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Datatypes\n",
        "\n"
      ],
      "metadata": {
        "id": "9x-m2P_X7pU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
        "1. Tensors not right datatype (eg. happens when inconsistent dtype substitution between tensors)\n",
        "2. Tensors not right shape (eg. happens in matrix multiplication)\n",
        "3. Tensors not on the right device (eg. device=\"cpu\" vs device=\"cuda\", and device agnostic code)"
      ],
      "metadata": {
        "id": "5hlfRLavbI2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.tensor([1.0, 2.0, 3.0], # even if dtype=None, PyTorch will then revert to default datatype\n",
        "                               dtype=None, # what datatype is the tensor (e.g float32 or float16)\n",
        "                               device=None, # what device is your tensor on\n",
        "                               requires_grad=False) # whether or not to track gradients with this tensor's operation\n",
        "print(float_32_tensor)\n",
        "print(float_32_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyiad9FQ7uEW",
        "outputId": "8d81c685-841e-477f-ad16-82d4bd3080ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = float_32_tensor.to(dtype=torch.float16) # convert float_32_tensor to float_16_tensor // alternatively, torch.half would also work\n",
        "print(float_16_tensor)\n",
        "print(float_16_tensor.dtype) # float_16_tensor is now float 16"
      ],
      "metadata": {
        "id": "Ac4tbfNB_mKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72baafcd-d2ac-42fe-b790-be199fe61a66"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# suprisingly no error raised even though discrepancy in dtype; normal behavious, but can be an issue with large neural network,\n",
        "# but preferably don't use different' dtype\n",
        "print(float_16_tensor * float_32_tensor) # works even if multipled by torch.long or torch.int32, etc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYBr0XYkANJq",
        "outputId": "d7dda52d-11a3-49c2-d217-ec7264878548"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 4., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Information from Tensors (Tensor Attributes)\n",
        "\n"
      ],
      "metadata": {
        "id": "QROJdy7bD0T-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Tensors not right datatype - to do get datatype from a tensor, can use `tensor.dtype`\n",
        "2. Tensors not right shape - to get a shape from a tensor, can use `tensor.shape`\n",
        "3. Tensors not on the right device - to get device from a tensor, can use `tensor.device`"
      ],
      "metadata": {
        "id": "5VnseeYobGF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a test tensor\n",
        "some_tensor = torch.rand(2, 3, 4)\n",
        "print(some_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rlMn3R_GFVI",
        "outputId": "21221e3c-869a-4c52-b71a-c5e7d83a0ee0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.4220, 0.1777, 0.6274, 0.5070],\n",
            "         [0.2611, 0.7993, 0.5080, 0.4965],\n",
            "         [0.5495, 0.5899, 0.1230, 0.3934]],\n",
            "\n",
            "        [[0.0251, 0.0667, 0.3379, 0.8956],\n",
            "         [0.4043, 0.7929, 0.4926, 0.7320],\n",
            "         [0.7707, 0.9150, 0.4982, 0.8741]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out details about some_tensor\n",
        "print(f\"Datatype of tensor : {some_tensor.dtype }\")\n",
        "print(f\"Shape of tensor    : {some_tensor.shape }\")  # \"some_tensor.shape\" and \"some_tensor.size()\" does the same thing (shape is attribute, .size() is founction)\n",
        "print(f\"Device of tensor   : {some_tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ8mtac0GGAq",
        "outputId": "8c0bc8e2-8afc-4d8b-d9d9-5dcdb1f0fdb6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype of tensor : torch.float32\n",
            "Shape of tensor    : torch.Size([2, 3, 4])\n",
            "Device of tensor   : cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensors (Tensor Operations)\n",
        "\n"
      ],
      "metadata": {
        "id": "iPHKgZUXK1KA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor Operations include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix Multiplication"
      ],
      "metadata": {
        "id": "OhTfE7inaiHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tensor\n",
        "tensor = torch.tensor([1, 2, 3]) # initialised from Python list or array\n",
        "print(tensor)\n",
        "print(tensor + 10) # addition\n",
        "print(tensor - 10) # subtraction\n",
        "print(tensor * 10) # multiplication\n",
        "print(tensor / 10) # division"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdF00hiMLhZ-",
        "outputId": "2ba8d8fe-7ef0-454b-8cb9-7e6f93f81c5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([11, 12, 13])\n",
            "tensor([-9, -8, -7])\n",
            "tensor([10, 20, 30])\n",
            "tensor([0.1000, 0.2000, 0.3000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try out PyTorch built-in functions\n",
        "print(torch.add(tensor, 10)) # addition\n",
        "print(torch.sub(tensor, 10)) # subtraction\n",
        "print(torch.mul(tensor, 10)) # multiplication\n",
        "print(torch.div(tensor, 10)) # division\n",
        "\n",
        "print(torch.abs(tensor)) # absolute value\n",
        "print(torch.sqrt(tensor)) # square root\n",
        "print(torch.exp(tensor)) # exponential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSAXIojJLzyz",
        "outputId": "ae525e5a-651c-42ff-e88a-9565f49cddef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11, 12, 13])\n",
            "tensor([-9, -8, -7])\n",
            "tensor([10, 20, 30])\n",
            "tensor([0.1000, 0.2000, 0.3000])\n",
            "tensor([1, 2, 3])\n",
            "tensor([1.0000, 1.4142, 1.7321])\n",
            "tensor([ 2.7183,  7.3891, 20.0855])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FT3gAnDZNi7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two main ways of performing multiplication in neural networks and deep learning are:\n",
        "1. Element-wise multiplication\n",
        "2. Matrix multiplication (dot product) [dot product and matrix multiplication is used interchangeably]\n",
        "\n",
        "URL: https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
        "\n",
        "Random Note: To multiply a matrix by another matrix, we need to do the \"dot product\" of rows and columns... (rewatch 3Blue1Brown if recap needed on linear algebra)\n",
        "\n",
        "---\n",
        "\n",
        "Regarding anatomy of Matrix, below as an example is a **4x2 matrix**, pay attention that the int*int order of matrix is classified by `_rows_x_columns_`. Use `tensor.shape`, to find the dimensions of the matrix:\n",
        "\n",
        "`[`\n",
        "\n",
        ">  `[1, 2],`\n",
        "\n",
        ">  `[3, 4],`\n",
        "\n",
        ">  `[5, 6],`\n",
        "\n",
        ">  `[7, 8]`\n",
        "\n",
        "`]`\n",
        "\n",
        "There are 2 main rules that performing matrix multiplication needs to satisfy:\n",
        "\n",
        "1. The **inner dimensions** must match:\n",
        "\n",
        "* `(3x2) @ (3x2)` <-- this won't work\n",
        "* `(2x3) @ (3x2)` <-- this will work\n",
        "* `(3x2) @ (2x2)` <-- this will work\n",
        "\n",
        "2. The resulting matrix has the shape of the **outer dimension**:\n",
        "\n",
        "* `(4x3) @ (3x6) = (4x6)` <-- 4x6 matrix outputted\n",
        "* `(3x1) @ (1x7) = (3x7)` <-- 3x7 matrix outputted\n",
        "\n",
        "\n",
        "> Note: regarding matrix multiplication syntax, `tensor @ tensor`, is the same as `torch.matmul(tensor, tensor)`, same performance wise etc, the '@' operator is an overload of the \\__matmul__ magic method in the PyTorch's tensor class."
      ],
      "metadata": {
        "id": "dPfobbYqafF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise Multiplication\n",
        "print(tensor, \"*\", tensor)\n",
        "print(f\"Equals: {tensor * tensor}\")\n",
        "\n",
        "print(torch.rand(4, 2).shape) # outputs the shape of a 4x2 matrix\n",
        "print((torch.rand(4, 3) @ torch.rand(3, 6)).shape) # 4x3 @ 3x6 -> 4x6\n",
        "print((torch.rand(3, 1) @ torch.rand(1, 7)).shape) # 3x1 @ 1x7 -> 3x7"
      ],
      "metadata": {
        "id": "g_F480MvNiqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4498b0d7-794a-45a3-c1c8-8bdbc9396a82"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n",
            "torch.Size([4, 2])\n",
            "torch.Size([4, 6])\n",
            "torch.Size([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Multiplication\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpXkhMZ4PttW",
        "outputId": "1c07ef75-64bf-4639-d6b3-14eae27313ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "value=0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Bf7C3xQCWX",
        "outputId": "f90c7b52-91c7-426d-d804-c772681533bc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14)\n",
            "CPU times: user 2.56 ms, sys: 1.11 ms, total: 3.67 ms\n",
            "Wall time: 6.73 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwZo9YICQqyc",
        "outputId": "c1d95baf-28c9-4b70-e285-433de25aa5e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.28 ms, sys: 55 Âµs, total: 1.34 ms\n",
            "Wall time: 1.36 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One of the Most Common Errors in Deep Learning: Shape Errors\n",
        "\n"
      ],
      "metadata": {
        "id": "eIwaJfMb9YyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes for Matrix Multiplication\n",
        "\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]])\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10, 1],\n",
        "                         [8, 11, 2]])\n",
        "\n",
        "#torch.mm(tensor_A, tensor_B)  # torch.mm() is the same as torch.matmul() // It's an Alias.\n",
        "torch.matmul(tensor_A, tensor_B) # As see, need to be 3x2 @ 2x3, which is multipliable. Which this outputs 3x3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auJ06dh8-K_S",
        "outputId": "d5e60027-87df-4df6-c00a-a3bf570ac475"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 23,  32,   5],\n",
              "        [ 53,  74,  11],\n",
              "        [ 83, 116,  17]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A way to fix our tensor shape issues, is that we can manipulate the shape of one of our tensors using a **transpose**.\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor."
      ],
      "metadata": {
        "id": "lsVwPHOl_F8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Shape:\", tensor_A.shape)\n",
        "print(\"Transposed Shape:\", tensor_A.T.shape)"
      ],
      "metadata": {
        "id": "oih1wrZE-GuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6269f093-5387-4571-b37a-320c398dde99"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Shape: torch.Size([3, 2])\n",
            "Transposed Shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the min, max, mean, sum, etc. (Tensor Aggregation)\n",
        "\n"
      ],
      "metadata": {
        "id": "aSCq3ZqZBBsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of \"Aggregation\": The formation of a number of things into a cluster.\n"
      ],
      "metadata": {
        "id": "9GD6BHXqbNQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tensor\n",
        "\n",
        "x = torch.arange(0, 100, 10)\n",
        "print(x)\n",
        "\n",
        "print(torch.min(x), x.min()) # Find the Min\n",
        "print(torch.max(x), x.max()) # Find the Max\n",
        "print(torch.mean(x.float()), x.type(torch.float32).mean()) # Find the Mean // When calculating mean, needs to be in float or complex dtype. Long doesn't work. Refer to MISC.\n",
        "print(torch.sum(x), x.sum()) # Find the Sum\n"
      ],
      "metadata": {
        "id": "uBSiMvbfBHv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c5f1a49-d193-4a59-8179-780c04d0924e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "tensor(0) tensor(0)\n",
            "tensor(90) tensor(90)\n",
            "tensor(45.) tensor(45.)\n",
            "tensor(450) tensor(450)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the Positional min and max"
      ],
      "metadata": {
        "id": "7uayyyXqEmXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x) # outputs \"tensor.arange(0, 100, 10)\"\n",
        "\n",
        "# Find the position in tensor that has the minimum value with \"argmin()\" -> returns index position of target tensor where the minimum value occurs\n",
        "print(x.argmin(), x[x.argmin()])\n",
        "\n",
        "# Find the position in tensor that has the maximum value with \"argmax()\" -> returns index position of target tensor where the maximum value occurs\n",
        "print(x.argmax(), x[x.argmax()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bfpLR4jEp3C",
        "outputId": "9f9d578f-c44e-4727-8564-7eb982a6667a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "tensor(0) tensor(0)\n",
            "tensor(9) tensor(90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping, Stacking, Squeezing and Unsqueezing Tensors\n",
        "\n"
      ],
      "metadata": {
        "id": "fzU4upg3F3d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Reshaping - Reshapes an input tensor to a defined shape, eg 1x12 matrix to a 2x6 matrix of a 4x3 matrix\n",
        "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
        "* Squeeze - removes all '1' dimensions from a tensor\n",
        "* Unsqueeze - add a '1' dimension to a target tensor\n",
        "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
      ],
      "metadata": {
        "id": "UpEBu9Diaqco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0., 12.)\n",
        "print(x, x.shape, '\\n')\n",
        "\n",
        "# Add an Extra Dimension -- tensor.reshape()\n",
        "x_reshaped = x.reshape(2, 6)  # reshapes input 1x12 matrix to 2x6 matrix\n",
        "print(\"Reshapes 1x12 matrix to 2x6 matrix\")\n",
        "print(x_reshaped, x_reshaped.shape, '\\n')\n",
        "\n",
        "x_reshaped = x.reshape(4, 3)  # reshapes input 1x12 matrix to 4x3 matrix\n",
        "print(\"Reshapes 1x12 matrix to 4x3 matrix\")\n",
        "print(x_reshaped, x_reshaped.shape, '\\n')\n",
        "\n",
        "# Quick note regarding tensor.shape\n",
        "#   For Scalar, it will results in \"torch.Size([])\"                    <-- indicating 0th dimension\n",
        "#   For Vector, it will results in \"torch.Size([int])\"                 <-- indicating 1st dimension\n",
        "#   For Matrix, it will results in \"torch.Size([int, int])\"            <-- indicating 2nd dimension\n",
        "#   For Tensor, it will results in \"torch.Size([int, int, int, ...])\"  <-- indicating 3+  dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR12jVwrGiNe",
        "outputId": "2ec4d604-6bac-407c-eacc-a9b7d1dd342b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]) torch.Size([12]) \n",
            "\n",
            "Reshapes 1x12 matrix to 2x6 matrix\n",
            "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.,  9., 10., 11.]]) torch.Size([2, 6]) \n",
            "\n",
            "Reshapes 1x12 matrix to 4x3 matrix\n",
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]]) torch.Size([4, 3]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newTensor = torch.arange(0., 12.)\n",
        "\n",
        "# Change the View -- tensor.view()\n",
        "tempView = newTensor.view(2, 6)\n",
        "print(tempView, tempView.shape)\n",
        "\n",
        "#Changing \"tempView\" tensor variable, changes \"x\" tensor variable (because a view of a tensor shares the same memory as the original input)\n",
        "tempView[:, 3] = 100  # refer to MISC regarding slicing\n",
        "print(\"\\n\", tempView)\n",
        "print(newTensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dso3LO4aIBCJ",
        "outputId": "5e663490-639f-4277-a8f8-3ac62f372adc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.,  9., 10., 11.]]) torch.Size([2, 6])\n",
            "\n",
            " tensor([[  0.,   1.,   2., 100.,   4.,   5.],\n",
            "        [  6.,   7.,   8., 100.,  10.,  11.]])\n",
            "tensor([  0.,   1.,   2., 100.,   4.,   5.,   6.,   7.,   8., 100.,  10.,  11.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack((x, x, x, x), dim=0)\n",
        "print(x_stacked, x_stacked.shape)\n",
        "x_stacked = torch.stack((x, x, x, x), dim=1)\n",
        "print(x_stacked, x_stacked.shape)\n",
        "\n",
        "x_stacked = torch.stack((x, x, x, x), dim=-1) # dim=-1 refers to last dimension of tensor\n",
        "print(x_stacked, x_stacked.shape)\n",
        "x_stacked = torch.stack((x, x, x, x), dim=-2) # dim=-2 refers to second to last dimension of tensor\n",
        "print(x_stacked, x_stacked.shape)\n",
        "\n",
        "# NOTE: Refer to MISC on Stack in PyTorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZl-Z-asuc3R",
        "outputId": "cd8ec6f8-f36f-41c0-f865-b25a00d9f0b1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n",
            "        [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n",
            "        [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n",
            "        [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]]) torch.Size([4, 12])\n",
            "tensor([[ 0.,  0.,  0.,  0.],\n",
            "        [ 1.,  1.,  1.,  1.],\n",
            "        [ 2.,  2.,  2.,  2.],\n",
            "        [ 3.,  3.,  3.,  3.],\n",
            "        [ 4.,  4.,  4.,  4.],\n",
            "        [ 5.,  5.,  5.,  5.],\n",
            "        [ 6.,  6.,  6.,  6.],\n",
            "        [ 7.,  7.,  7.,  7.],\n",
            "        [ 8.,  8.,  8.,  8.],\n",
            "        [ 9.,  9.,  9.,  9.],\n",
            "        [10., 10., 10., 10.],\n",
            "        [11., 11., 11., 11.]]) torch.Size([12, 4])\n",
            "tensor([[ 0.,  0.,  0.,  0.],\n",
            "        [ 1.,  1.,  1.,  1.],\n",
            "        [ 2.,  2.,  2.,  2.],\n",
            "        [ 3.,  3.,  3.,  3.],\n",
            "        [ 4.,  4.,  4.,  4.],\n",
            "        [ 5.,  5.,  5.,  5.],\n",
            "        [ 6.,  6.,  6.,  6.],\n",
            "        [ 7.,  7.,  7.,  7.],\n",
            "        [ 8.,  8.,  8.,  8.],\n",
            "        [ 9.,  9.,  9.,  9.],\n",
            "        [10., 10., 10., 10.],\n",
            "        [11., 11., 11., 11.]]) torch.Size([12, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_reshaped)\n",
        "print(x_reshaped.shape, '\\n')\n",
        "\n",
        "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim (dimension)\n",
        "x_unsqueezed = x_reshaped.unsqueeze(dim=0).unsqueeze(dim=2) # turns torch.Size([4, 3]) to torch.Size([1, 4, 1, 3])    // adding 2 dimensions in this case\n",
        "\n",
        "print(x_unsqueezed)\n",
        "print(x_unsqueezed.shape, '\\n')\n",
        "\n",
        "# torch.squeeze() - removes all single dimensions from a target tensor\n",
        "x_squeezed = x_reshaped.squeeze() # turns torch.Size([1, 4, 1, 3]) to torch.Size([4, 3]) // All single-dimensions removed\n",
        "\n",
        "print(x_squeezed)\n",
        "print(x_squeezed.shape, '\\n')"
      ],
      "metadata": {
        "id": "h6qmKxT1ucli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6e74f2-dc6c-4b89-c5c8-ec53c11f35a5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]])\n",
            "torch.Size([4, 3]) \n",
            "\n",
            "tensor([[[[ 0.,  1.,  2.]],\n",
            "\n",
            "         [[ 3.,  4.,  5.]],\n",
            "\n",
            "         [[ 6.,  7.,  8.]],\n",
            "\n",
            "         [[ 9., 10., 11.]]]])\n",
            "torch.Size([1, 4, 1, 3]) \n",
            "\n",
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]])\n",
            "torch.Size([4, 3]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.permute() - rearranges the dimensions of a target tensor in a specified order\n",
        "colour = torch.rand(size=(4, 6, 3))\n",
        "print(colour)                         # [height, width, colour_channels]\n",
        "print(colour.shape, '\\n')\n",
        "\n",
        "# Permute the original colour tensor to rearrange the axis (or dim) order\n",
        "colour_permuted = colour.permute(2, 0, 1) # turns torch.Size([4, 3]) to torch.Size([3, 4])\n",
        "\n",
        "print(colour_permuted)\n",
        "print(colour_permuted.shape, '\\n')    # [colour_channels, height, width]\n",
        "\n",
        "# Indexing -- Original + Permuted\n",
        "print(colour[1, 5, 2], colour_permuted[2, 1, 5]) # both this line and below accesses the same value, notice how their ith index is changed based on .permute() ordering\n",
        "print(colour[2, 1, 2], colour_permuted[2, 2, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNZVFdq23e7P",
        "outputId": "0c512b2b-11de-44f3-e4b4-ee18328fd322"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.8987, 0.1504, 0.7831],\n",
            "         [0.1949, 0.7430, 0.1381],\n",
            "         [0.4506, 0.0641, 0.9216],\n",
            "         [0.6601, 0.7801, 0.0390],\n",
            "         [0.9887, 0.2105, 0.5448],\n",
            "         [0.1835, 0.6150, 0.4326]],\n",
            "\n",
            "        [[0.2583, 0.8937, 0.6003],\n",
            "         [0.4536, 0.0735, 0.6484],\n",
            "         [0.6436, 0.9835, 0.2535],\n",
            "         [0.5457, 0.1390, 0.8481],\n",
            "         [0.7183, 0.9208, 0.3214],\n",
            "         [0.1480, 0.8678, 0.7758]],\n",
            "\n",
            "        [[0.2079, 0.0541, 0.8964],\n",
            "         [0.5032, 0.0816, 0.6990],\n",
            "         [0.4493, 0.0773, 0.3050],\n",
            "         [0.3787, 0.2513, 0.6509],\n",
            "         [0.2784, 0.4532, 0.0607],\n",
            "         [0.8046, 0.1965, 0.7660]],\n",
            "\n",
            "        [[0.9633, 0.6317, 0.0680],\n",
            "         [0.1485, 0.8863, 0.6642],\n",
            "         [0.5199, 0.1377, 0.6971],\n",
            "         [0.9700, 0.9300, 0.3529],\n",
            "         [0.7233, 0.5011, 0.0073],\n",
            "         [0.2435, 0.9157, 0.4473]]])\n",
            "torch.Size([4, 6, 3]) \n",
            "\n",
            "tensor([[[0.8987, 0.1949, 0.4506, 0.6601, 0.9887, 0.1835],\n",
            "         [0.2583, 0.4536, 0.6436, 0.5457, 0.7183, 0.1480],\n",
            "         [0.2079, 0.5032, 0.4493, 0.3787, 0.2784, 0.8046],\n",
            "         [0.9633, 0.1485, 0.5199, 0.9700, 0.7233, 0.2435]],\n",
            "\n",
            "        [[0.1504, 0.7430, 0.0641, 0.7801, 0.2105, 0.6150],\n",
            "         [0.8937, 0.0735, 0.9835, 0.1390, 0.9208, 0.8678],\n",
            "         [0.0541, 0.0816, 0.0773, 0.2513, 0.4532, 0.1965],\n",
            "         [0.6317, 0.8863, 0.1377, 0.9300, 0.5011, 0.9157]],\n",
            "\n",
            "        [[0.7831, 0.1381, 0.9216, 0.0390, 0.5448, 0.4326],\n",
            "         [0.6003, 0.6484, 0.2535, 0.8481, 0.3214, 0.7758],\n",
            "         [0.8964, 0.6990, 0.3050, 0.6509, 0.0607, 0.7660],\n",
            "         [0.0680, 0.6642, 0.6971, 0.3529, 0.0073, 0.4473]]])\n",
            "torch.Size([3, 4, 6]) \n",
            "\n",
            "tensor(0.7758) tensor(0.7758)\n",
            "tensor(0.6990) tensor(0.6990)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Miscellaneous\n"
      ],
      "metadata": {
        "id": "rQlIt0Bharsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Miscellaneous Notes - Image Tensor"
      ],
      "metadata": {
        "id": "eTWxoO1k0yFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Prompt:** In tensor-speak (the language used to describe tensors), the tensor would have three dimensions, one for colour_channels, height and width.\n",
        "\n",
        "<br>\n",
        "\n",
        "**GPT Answer:**\n",
        "\n",
        "The quote you've provided talks about how to describe the structure of a tensor, particularly in the context of image data, using the specific terminology or \"language\" associated with tensors.\n",
        "\n",
        "In the realm of machine learning and computer vision, images are commonly represented as tensors. A tensor, in this context, is essentially a multi-dimensional array. For an image, these dimensions correspond to different aspects of the data it contains:\n",
        "\n",
        "Color Channels: The number of channels in an image represents the depth of color information. For instance, a standard RGB (Red, Green, Blue) image has three color channels. Each channel stores intensity values for its respective color across the image. There are also grayscale images, which have just one channel, and other formats that may have more channels (like RGBA, where the A stands for Alpha or transparency).\n",
        "\n",
        "Height: This dimension represents the vertical size of the image in pixels.\n",
        "\n",
        "Width: This dimension represents the horizontal size of the image in pixels.\n",
        "\n",
        "So, when the quote mentions a tensor having \"three dimensions, one for color_channels, height, and width,\" it's describing how an image is structured in a way that's understood by tensor operations. For a color image in the RGB format, you could conceptualize it as a 3D tensor:\n",
        "\n",
        "The first dimension corresponds to the color channels (3 for RGB).\n",
        "The second dimension corresponds to the height of the image in pixels.\n",
        "The third dimension corresponds to the width of the image in pixels.\n",
        "Thus, if you have a 1080x1920 pixel RGB image, in tensor-speak, you would describe it as having dimensions of 3x1080x1920, where 3 represents the RGB channels, 1080 represents the height, and 1920 represents the width.\n",
        "\n",
        "Understanding this terminology is crucial for working with image data in machine learning frameworks like TensorFlow or PyTorch, as it affects how you process, manipulate, and train models with image data.\n",
        "\n",
        "<br>\n",
        "---\n",
        "<br>\n",
        "\n",
        "Here's an example of what a tensor array for a 10x10 image with RGBA channels might look like. Each entry in this array is a randomly generated integer between 0 and 255, representing the intensity of the Red, Green, Blue, and Alpha (transparency) channels at each pixel:\n",
        "\n",
        "---\n",
        "```\n",
        "Array shape: (4, 10, 10)\n",
        "\n",
        "array([[[203, 178,  63, 203,  19,  80,  77,  99, 226, 227], #red\n",
        "        [148,  31, 141, 150, 187, 184, 214,  10,  40,  95],\n",
        "        [ 96,  76, 213, 117,  79, 224, 174,  44,   7, 236],\n",
        "        [182,  25, 242, 120, 207, 194,  52,  38,  42, 222],\n",
        "        [105, 193, 169, 146, 221,  76, 179,  84, 109, 222],\n",
        "        [  4, 105,  73,  54, 242, 172, 238,  23,  89, 192],\n",
        "        [ 79,  26,  75, 133,  92,  10, 115, 114,  87, 227],\n",
        "        [124, 183,  36, 176, 115, 246, 151, 227,  54,   1],\n",
        "        [  8, 255, 102, 242, 116,  93,  10, 184, 184,   1],\n",
        "        [161, 118,  98, 150,  89, 208,  76,  77,  58, 136]],\n",
        "\n",
        "       [[171, 231, 224, 128, 149, 101,  72, 167,  57, 178], #green\n",
        "        [170,   3, 175, 194, 243,  77, 188,  97, 197, 206],\n",
        "        [250, 197,  22, 191, 215, 156,  73,  38, 196,  34],\n",
        "        [255, 164, 187,  28, 114, 140,  65, 162,  74, 168],\n",
        "        [212, 127, 120, 162,  86,  22, 141, 126,  81, 167],\n",
        "        [168, 201,  21, 219, 148,  70, 102, 206, 111, 214],\n",
        "        [ 23, 204, 152,  56, 164, 110, 197, 213,  28, 206],\n",
        "        [162, 149, 100, 206,  25,  88, 161,  83, 173, 177],\n",
        "        [218,  38,  76, 220,  37,  36,  11, 228,   0, 107],\n",
        "        [ 29,  94, 173, 170,  31, 207, 251,  65, 205,  95]],\n",
        "\n",
        "       [[ 17, 117, 145,  64, 124,  20, 242, 202, 159,  72], #blue\n",
        "        [214, 102, 124, 170, 191,  93,  23, 251, 249,  62],\n",
        "        [ 25, 245, 169, 116, 131,  39,  68, 147,  79,  90],\n",
        "        [111,  33,  35, 196, 197, 170,  51, 197,  62,  70],\n",
        "        [ 47,  41, 113, 166, 202,  24, 242, 246,  68, 245],\n",
        "        [174,   4,  77,  83,  42,  65, 183,  58, 113,  44],\n",
        "        [221, 117, 252, 153, 119,  45, 137, 104,  58,  57],\n",
        "        [168, 231, 210, 239,  32,  30,   9, 150,  95, 214],\n",
        "        [127, 240,  56, 200, 161, 137, 197,   6, 231,  72],\n",
        "        [  4, 109,  53,  11, 197, 217,  88,   1, 249, 254]],\n",
        "\n",
        "       [[ 23, 252, 127,   8,  58, 222, 123,   6,  14, 108], #alpha\n",
        "        [  4, 195,  26, 177,  59, 145, 199, 167, 181,  93],\n",
        "        [  4, 119, 204, 182, 108,  53, 175, 159,  83,  50],\n",
        "        [ 47, 233, 103, 198,  84, 134,  42, 145,  93, 235],\n",
        "        [ 35, 165, 152,  77, 101, 153, 242, 206, 109,   9],\n",
        "        [ 78, 210, 182, 151,  48, 209, 199,  33, 138,  95],\n",
        "        [226, 206, 106,  47,  54,  49, 178, 107, 112, 105],\n",
        "        [195,  17,  24, 144,  91,  14, 102, 123, 246, 231],\n",
        "        [253, 137,  22, 133,  19, 192, 166,  24, 145,  78],\n",
        "        [ 69, 165, 135, 255, 122, 125, 135, 160, 174,  54]]], dtype=uint8)\n",
        "```\n",
        "---\n",
        "\n",
        "This representation shows a 4-dimensional tensor where:\n",
        "\n",
        "* The first dimension corresponds to the color channels (RGBA), so there are 4 layers or slices.\n",
        "* The second and third dimensions correspond to the height and width of the image, respectively, both set to 10 pixels in this example.\n",
        "\n",
        "Each \"layer\" or slice of the tensor represents one of the RGBA channels across the entire image. The values within each layer represent the intensity of that channel for each pixel, with 0 being no intensity (or completely transparent for the alpha channel) and 255 being the maximum intensity. â€‹â€‹\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VwkYilIn02Ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Jupyter notebooks, which include Google Colab notebooks, you do not always need to use the print() function to display output. This environment is designed for interactive computing, and it has a feature that automatically displays the result of the last operation in each cell.\n",
        "\n",
        "When you run a cell in a Jupyter notebook (or Google Colab, which is based on Jupyter), the following rules apply:\n",
        "\n",
        "The last line of code in a cell, when executed, will have its result displayed below the cell, even if it is not printed with the print() function. This is known as the cell's output.\n",
        "If the last line of code does not produce any output, nothing is displayed.\n",
        "If you have other lines of code in the cell whose output you wish to display, you need to explicitly use print() or another display function for those lines.\n",
        "This feature is especially useful for quick data exploration and analysis, as it allows you to see the results immediately without needing to use print() every time. However, if you want to format the output or display multiple outputs within a cell, you'll need to use print() or another suitable display function."
      ],
      "metadata": {
        "id": "Yj1fmRysZZ6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes Regarding Why you don't need to declare print() to output value in Google Colab**\n",
        "\n",
        "<br>\n",
        "\n",
        "In Jupyter notebooks, which include Google Colab notebooks, you do not always need to use the $print()$ function to display output. This environment is designed for interactive computing, and it has a feature that automatically displays the result of the last operation in each cell.\n",
        "\n",
        "When you run a cell in a Jupyter notebook (or Google Colab, which is based on Jupyter), the following rules apply:\n",
        "\n",
        "1. The last line of code in a cell, when executed, will have its result displayed below the cell, even if it is not printed with the $print()$ function. This is known as the cell's output.\n",
        "2. If the last line of code does not produce any output, nothing is displayed.\n",
        "3. If you have other lines of code in the cell whose output you wish to display, you need to explicitly use $print()$ or another display function for those lines.\n",
        "\n",
        "\n",
        "This feature is especially useful for quick data exploration and analysis, as it allows you to see the results immediately without needing to use $print()$ every time. However, if you want to format the output or display multiple outputs within a cell, you'll need to use $print()$ or another suitable display function."
      ],
      "metadata": {
        "id": "LaRNJIfGZdoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miscellaneous Notes - Dimensions"
      ],
      "metadata": {
        "id": "Y_VYrwjwt_S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Prompt**: what even is ndim in torch, as in, what is dimension of tensors even. as scalars are normally assosciated with the number line 1st dimension, however here it is assosicated with the 0th dimension. can i know why does tensorflow consider scalar as 0th, vector as 1st, matrix 2nd etc\n",
        "\n",
        "<br>\n",
        "\n",
        "**GPT Answer**:\n",
        "\n",
        "The concept of dimensionality in tensors (as used in libraries like PyTorch and TensorFlow) is rooted in the mathematical definition of dimensions in linear algebra, but it's also slightly adapted to fit programming and data structure paradigms.\n",
        "\n",
        "**Understanding Dimensions**\n",
        "\n",
        "* Dimensionality: In the context of tensors, the dimensionality (or rank) refers to the number of indices required to uniquely select each element of the tensor. This concept is directly tied to how data can be organized and represented in structured forms:\n",
        "> * A scalar can be thought of as a single number. It doesn't contain any axes (or directions), so it's considered 0-dimensional. You don't need any index to access it because it's just a single value.\n",
        "> * A vector is a 1-dimensional array. You need one index to access each element. Think of it as a line where each element can be located at a certain position along that line.\n",
        "> * A matrix is a 2-dimensional array. You need two indices to access each element (one for the row and one for the column). It can be visualized as a plane or grid where positions are defined by two coordinates.\n",
        "> * Higher-dimensional tensors (3D, 4D, etc.) require more indices to access each element and represent more complex structures (like a cube for a 3D tensor).\n",
        "\n",
        "**Why Scalars are Considered 0-Dimensional**\n",
        "\n",
        "The designation of scalars as 0-dimensional in libraries like TensorFlow and PyTorch is consistent with how dimensions are mathematically defined. Since a scalar does not require any indices to access (it's just a single value), it is considered 0-dimensional. This definition helps maintain consistency across mathematical theory and its implementation in programming:\n",
        "\n",
        "* It aligns with the mathematical concept of a dimension as the number of coordinates needed to specify a point within it.\n",
        "* It provides a basis for defining operations and transformations on tensors in a way that is consistent regardless of their rank.\n",
        "\n",
        "**Practical Implications**\n",
        "\n",
        "This conceptual framework has practical implications in programming and data processing:\n",
        "\n",
        "* Generalization: By defining a scalar as a 0-dimensional tensor, vectors as 1-dimensional, matrices as 2-dimensional, and so on, libraries can offer a unified and consistent API for tensor operations that works across tensors of any dimensionality.\n",
        "* Broadcasting and Shape Manipulation: Understanding dimensionality is crucial for operations that involve multiple tensors, especially when their shapes differ. It allows for the implementation of broadcasting rules, where tensors of different shapes are used together in operations.\n",
        "* Data Representation: This hierarchical structure (scalar < vector < matrix < tensor) provides an intuitive way to represent increasingly complex data. For instance, a 3D tensor could represent a sequence of images (2D tensors), where each image is a matrix of pixel values.\n",
        "\n",
        "In summary, the classification of scalars as 0-dimensional and so on up the hierarchy to higher-dimensional tensors is a logical extension of mathematical principles into programming constructs, allowing for more versatile and powerful data manipulation capabilities in libraries like PyTorch and TensorFlow."
      ],
      "metadata": {
        "id": "MuZGa5V3uICX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miscellaneous Notes - tensor.mean() Dtype 'Long' issue"
      ],
      "metadata": {
        "id": "ZQD8bpqOChsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Prompt:** Why does long not work with .mean() in PyTorch\n",
        "\n",
        "**GPT Answer:** In PyTorch, the .mean() operation computes the arithmetic mean of all the elements in the tensor. For the mean to be meaningful, especially in the context of floating-point arithmetic, the operation is defined only for tensors with floating point or complex numbers. This is because the mean is not always an integer value, and rounding to an integer could lead to loss of precision and incorrect calculations in subsequent operations.\n",
        "\n",
        "The tensor you are working with has been created with the default integer type (torch.int64 or Long type in PyTorch), as inferred from the torch.arange function. To calculate the mean, you need to first convert it to a floating-point type. You can do this by using the .float() or .to() methods on the tensor.\n",
        "\n",
        "Here's how you can modify your tensor to compute the mean:\n",
        "\n",
        "```\n",
        "x_float = x.float()  # Convert x to a float tensor\n",
        "print(torch.mean(x_float), x_float.mean())  # Now you can compute the mean\n",
        "```\n",
        "\n",
        "This converts the tensor x to a floating point tensor (torch.float32), which allows the .mean() method to work correctly."
      ],
      "metadata": {
        "id": "dmh06M5UEgXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miscellaneous Notes - Regarding Slicing [:] in Python"
      ],
      "metadata": {
        "id": "5dWcE3rWMski"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Answer Regarding Slicing[:] in Python**\n",
        "In Python, slicing is a feature that allows you to access a portion of a sequence type (like lists, strings, tuples) or array-like objects (like NumPy arrays and PyTorch tensors). The slicing operator [:] is used to access elements of an iterable based on their indices. Here are some examples of how slicing works:\n",
        "\n",
        "---\n",
        "\n",
        "**Lists**\n",
        "\n",
        "* Let's start with a simple list:\n",
        "> `my_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`\n",
        "* Accessing all elements:\n",
        "> `all_elements = my_list[:]  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`\n",
        "* Accessing the first 5 elements:\n",
        "> `first_five = my_list[:5]  # [0, 1, 2, 3, 4]`\n",
        "* Accessing elements from index 5 to the end:\n",
        "> `from_five_onwards = my_list[5:]  # [5, 6, 7, 8, 9]`\n",
        "* Accessing elements from index 3 to 7 (not including 7):\n",
        "> `subset = my_list[3:7]  # [3, 4, 5, 6]`\n",
        "* Accessing elements with a step (every second element):\n",
        "> `every_second = my_list[::2]  # [0, 2, 4, 6, 8]`\n",
        "* Accessing elements in reverse:\n",
        "> `reversed_list = my_list[::-1]  # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]`\n",
        "\n",
        "---\n",
        "\n",
        "**Strings**\n",
        "\n",
        "* Slicing works similarly with strings:\n",
        "> `my_string = \"Hello, World!\"`\n",
        "\n",
        "* Accessing all characters:\n",
        "> `all_chars = my_string[:]  # \"Hello, World!\"`\n",
        "\n",
        "* Accessing the first 5 characters:\n",
        "> `first_five = my_string[:5]  # \"Hello\"`\n",
        "\n",
        "* Accessing characters from index 7 to the end:\n",
        "> `from_seven_onwards = my_string[7:]  # \"World!\"`\n",
        "\n",
        "---\n",
        "\n",
        "**NumPy Arrays**\n",
        "\n",
        "* For NumPy arrays (and similarly for PyTorch tensors), slicing can be multidimensional:\n",
        "\n",
        "> ```\n",
        "import numpy as np\n",
        "my_array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "> ```\n",
        "\n",
        "* Accessing the entire array:\n",
        "> `all_elements = my_array[:]  # array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])`\n",
        "\n",
        "* Accessing the first two rows:\n",
        "> `first_two_rows = my_array[:2]  # array([[1, 2, 3], [4, 5, 6]])`\n",
        "\n",
        "* Accessing the second column:\n",
        "> `second_column = my_array[:, 1]  # array([2, 5, 8])`\n",
        "\n",
        "Accessing a submatrix (first two rows, last two columns):\n",
        "> `submatrix = my_array[:2, 1:]  # array([[2, 3], [5, 6]])`\n",
        "\n",
        "---\n",
        "\n",
        "Slicing is a powerful tool in Python that lets you retrieve elements efficiently from sequences and array-like objects without the need for explicit loops."
      ],
      "metadata": {
        "id": "dYvo2hNeVVti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miscellaneous Notes - torch.stack() + torch.squeeze()\n",
        "\n"
      ],
      "metadata": {
        "id": "O0K3zfBbwa16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### torch.stack(), torch.vstack(), torch.hstack()\n",
        "\n",
        "GPT Prompt: Explain to me what does `torch.stack()` do?\n",
        "\n",
        "GPT Answer:\n",
        "\n",
        "`torch.stack()` is a function in PyTorch, a popular open-source machine learning library, that is used to concatenate a sequence of tensors along a new dimension. All tensors in the sequence **must have the same shape**. The function is particularly useful when you want to combine tensors in a way that creates an additional dimension, rather than simply joining them end-to-end as in concatenation.\n",
        "\n",
        "Here's a more detailed breakdown of its functionality:\n",
        "\n",
        "* Parameters: The `torch.stack(tensors, dim=0, *, out=None) -> Tensor` function takes several parameters, the most important of which are:\n",
        "\n",
        "  * tensors: a sequence of tensors to concatenate. These tensors must all have the same shape.\n",
        "  * dim: the dimension along which to concatenate the tensors. This is a new dimension that the tensors will be stacked along.\n",
        "  * out (Tensor, optional) â€“ the output tensor.\n",
        "\n",
        "* Behavior: `torch.stack()` joins a sequence of tensors along a new dimension. All tensors in the sequence are expanded to have one additional dimension, and then they are joined along this new dimension. The position of this new dimension in the resultant tensor is specified by the dim parameter.\n",
        "\n",
        "* Result: The result of `torch.stack()` is a new tensor with one more dimension than the original tensors. For example, if you stack three 2D tensors (each of shape [2, 3]) along a new first dimension (`dim=0`), the resulting tensor will have the shape [3, 2, 3].\n",
        "\n",
        "Here's an example to illustrate its use:\n",
        "\n",
        " ```\n",
        "import torch\n",
        "\n",
        "# Creating two 2D tensors of shape [2, 3]\n",
        "tensor1 = torch.randn(2, 3)\n",
        "tensor2 = torch.randn(2, 3)\n",
        "\n",
        "# Stacking the two tensors along a new dimension (creates a new dimension at position 0)\n",
        "result = torch.stack((tensor1, tensor2), dim=0)\n",
        "\n",
        "print(result.shape)  # Output will be: torch.Size([2, 2, 3])\n",
        "```\n",
        "\n",
        "In this example, tensor1 and tensor2 are stacked along a new first dimension (dim=0), resulting in a tensor of shape [2, 2, 3], indicating that there are 2 tensors, each of shape [2, 3], stacked together.\n",
        "\n",
        "---\n",
        "GPT Prompt: Then what does param dim=-1 and dim=-2 do?\n",
        "\n",
        "GPT Answer:\n",
        "\n",
        "In PyTorch, `torch.stack()` is a function used to concatenate a sequence of tensors along a new dimension. All tensors in the sequence must have the same shape. The function creates a new tensor by stacking the input tensors, effectively adding one additional dimension to the resultant tensor, where each input tensor becomes a slice along the newly created dimension.\n",
        "\n",
        "The `dim` parameter in `torch.stack()` specifies the dimension along which the tensors are stacked. The dimensions are zero-indexed, meaning dim=0 would stack the tensors along a new first dimension, and the original dimensions of the tensors would follow after this new dimension.\n",
        "\n",
        "Regarding `dim=-1` and `dim=-2`:\n",
        "\n",
        "* `dim=-1` refers to the last dimension of the tensor. When you use dim=-1 in torch.stack(), it means you're stacking the tensors along the last dimension. After stacking, this newly created dimension becomes the new last dimension of the resultant tensor.\n",
        "\n",
        "* `dim=-2` refers to the second-to-last dimension of the tensor. Using dim=-2 in torch.stack() means the tensors are stacked along the second-to-last dimension, making the newly created dimension the new second-to-last dimension of the resultant tensor.\n",
        "\n",
        "These negative indices are useful for specifying dimensions relative to the end of the tensor, which can be especially handy when you're dealing with tensors of varying dimensions and you want to stack them along one of the last few dimensions without explicitly calculating or hard-coding the dimension index.\n",
        "\n",
        "---\n",
        "\n",
        "GPT Prompt: Then what is torch.vstack() and torch.hstack()\n",
        "\n",
        "GPT Answer:\n",
        "\n",
        "In PyTorch, torch.vstack() and torch.hstack() are functions used to concatenate tensors vertically and horizontally, respectively. These functions provide a convenient way to stack tensors along specific axes and are particularly useful when working with 2D tensors (matrices) but can also be applied to tensors with more dimensions. Here's a brief overview of each:\n",
        "\n",
        "`torch.vstack()`\n",
        "\n",
        "* **Vertical stacking (vstack):** This function stacks tensors vertically, which is equivalent to concatenating tensors along the first dimension (rows) for 2D tensors, or more generally, along a new first dimension for tensors of any shape. It's akin to stacking matrices on top of each other or appending rows to a matrix.\n",
        "* **Usage:** It's commonly used when you have tensors of the same width (i.e., the same size in all dimensions except for the first) and you want to combine them into a single tensor with greater height (more rows).\n",
        "\n",
        "`torch.hstack()`\n",
        "\n",
        "* **Horizontal stacking (hstack):** This function stacks tensors horizontally, equivalent to concatenating tensors along the second dimension (columns) for 2D tensors, or more generally, along the last dimension for 1D tensors. For tensors with more than two dimensions, it concatenates along the last dimension, which increases the size of that dimension.\n",
        "* **Usage:** It's used when you have tensors of the same height (i.e., the same size in all dimensions except for the second in the case of 2D tensors) and you want to combine them into a single tensor with greater width (more columns).\n",
        "\n",
        "These functions are particularly helpful in data manipulation and preprocessing tasks, such as combining data from different sources into a single dataset or reshaping data to fit the input requirements of a model."
      ],
      "metadata": {
        "id": "SSpMm-0nwnJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Prompt:** Explain to me regarding torch.squeeze() and torch.unsqueeze()\n",
        "\n",
        "**GPT Answer:**\n",
        "\n",
        "In PyTorch, `torch.squeeze()` and `torch.unsqueeze()` are two functions used for modifying the dimensions of tensors, specifically for removing and adding dimensions of size 1, respectively. These functions are very useful for tensor shape manipulation, allowing for more flexible operations and easier integration with APIs expecting certain tensor shapes.\n",
        "\n",
        "<br>\n",
        "\n",
        "`torch.squeeze()`\n",
        "\n",
        "* Purpose: Removes all dimensions of size 1 from the tensor. If a specific dimension is given as an argument, torch.squeeze() removes the given dimension only if it is of size 1; otherwise, the tensor is returned unchanged.\n",
        "* Usage: This is useful when you want to eliminate redundant dimensions from your tensor, making your data more compact or ensuring it fits certain APIs that do not accept tensors with singleton dimensions. For example, if you have a tensor of shape (1, 3, 1, 5), applying squeeze() would reduce its shape to (3, 5).\n",
        "* Parameter:\n",
        "  * input (Tensor) â€“ the input tensor.\n",
        "  * dim (int or tuple of ints, optional) â€“ if given, the input will be squeezed only in the specified dimensions.\n",
        "* Syntax Example:\n",
        "> `squeezed_tensor = torch.squeeze(input_tensor, dim=None)`\n",
        "\n",
        "  Here, input_tensor is the tensor you want to squeeze, and dim is an optional argument specifying the dimension to squeeze. If dim is not provided, all dimensions of size 1 are removed.\n",
        "\n",
        "`torch.unsqueeze()`\n",
        "\n",
        "* Purpose: Adds a dimension of size 1 to the tensor at the specified dimension. This is the inverse operation of squeeze(), allowing you to expand the dimensions of your tensor.\n",
        "* Usage: This is particularly useful when you need to increase the dimensionality of a tensor for it to be compatible with certain operations that expect tensors of a certain shape. For instance, if you have a tensor of shape (3, 5) and you want to add a singleton dimension as the first dimension, you would end up with a shape of (1, 3, 5).\n",
        "* Syntax Example:\n",
        "> `unsqueezed_tensor = torch.unsqueeze(input_tensor, dim)`\n",
        "\n",
        "  Here, input_tensor is the tensor you want to unsqueeze, and dim is the position where the new dimension will be inserted.\n",
        "\n",
        "Both `squeeze()` and `unsqueeze()` are essential for shaping tensors in preparation for various operations, such as matrix multiplications, broadcasting, and feeding data into models, ensuring that tensors conform to the expected dimensions.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cCoqU4C1ywkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miscellaneous Notes - torch.permute()\n"
      ],
      "metadata": {
        "id": "ZrINWfJI3r5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, `torch.permute()` is a function used to rearrange the dimensions of a tensor according to a specified order. This allows for complex reshaping and reordering of the data within a tensor, making it a powerful tool for manipulating tensor shapes and dimensions.\n",
        "\n",
        "---\n",
        "\n",
        "How `torch.permute()` Works\n",
        "\n",
        "* Purpose: To reorder the dimensions of a tensor.\n",
        "* Usage: When you want to change the order of axes/dimensions of a tensor. For example, if you have a tensor of shape (2, 3, 4) and you want to change the order of dimensions to make it (3, 4, 2), you can use torch.permute() to achieve this.\n",
        "\n",
        "---\n",
        "\n",
        "Syntax and Example\n",
        "```\n",
        "import torch\n",
        "\n",
        "# Creating a tensor of shape (2, 3, 4)\n",
        "x = torch.randn(2, 3, 4)\n",
        "\n",
        "# Permute the dimensions\n",
        "# Here, we want the dimension order to be (1, 2, 0),\n",
        "# meaning the new shape will be (3, 4, 2)\n",
        "y = x.permute(1, 2, 0)\n",
        "\n",
        "print(\"Original shape:\", x.shape)\n",
        "print(\"New shape:\", y.shape)\n",
        "```\n",
        "\n",
        "In the permute(1, 2, 0) call, the arguments represent the new order of the dimensions:\n",
        "\n",
        "* The first dimension (0) of x becomes the third dimension of y.\n",
        "* The second dimension (1) of x becomes the first dimension of y.\n",
        "* The third dimension (2) of x becomes the second dimension of y.\n",
        "\n",
        "This results in y having a shape of (3, 4, 2), as per the example.\n",
        "\n",
        "**Key Points**\n",
        "\n",
        "* `torch.permute()` does not change the data within the tensor; it only changes how the data is organized by rearranging the tensor dimensions.\n",
        "* It's useful for operations that require specific dimension orders, such as when preparing data for convolutional layers in neural networks, where you might need to permute dimensions to match the expected input shape.\n",
        "\n",
        "This flexibility makes `torch.permute()` an essential function for tensor manipulation, especially in complex data processing pipelines and neural network operations."
      ],
      "metadata": {
        "id": "fJXz4z5t3xNr"
      }
    }
  ]
}