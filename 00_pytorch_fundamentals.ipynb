{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eTWxoO1k0yFp",
        "Y_VYrwjwt_S2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Resource Link: https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises"
      ],
      "metadata": {
        "id": "fPCWsihGzXzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOSmuwB2LEhj",
        "outputId": "26d98f83-9a43-4edb-9d73-f370b9d0537c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ESnUlcanGGd3"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Tensors\n",
        "\n",
        "### Creating Tensors\n",
        "\n",
        "PyTorch tensors are created using torch.Tensor() = https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "---\n",
        "\n",
        "* Scalar (Rank 0 Tensor): A scalar is a single number. In PyTorch, you create a scalar by passing a single value to torch.tensor(). The code creates a scalar with a value of 7. .ndim checks the number of dimensions (which is 0 for a scalar), .shape returns an empty tuple since scalars have no dimensions, and .item() converts the tensor scalar to a standard Python scalar.\n",
        "\n",
        "* Vector (Rank 1 Tensor): A vector is a 1-dimensional array of numbers. The code creates a vector [7, 7] using torch.tensor(). Here, .ndim returns 1 indicating it's 1-dimensional, and .shape returns (2), meaning the vector has 2 elements.\n",
        "\n",
        "* Matrix (Rank 2 Tensor): A matrix is a 2-dimensional array of numbers. The example creates a 2x2 matrix with torch.tensor([[7, 8], [9, 10]]). .ndim shows it's 2-dimensional, and .shape returns (2, 2), indicating 2 rows and 2 columns.\n",
        "\n",
        "* Higher-Dimensional Tensor (Rank 3+ Tensor): Tensors can have three or more dimensions. The provided code creates a tensor with dimensions (1, 3, 3), meaning it contains a 3x3 matrix in a 3-dimensional space. .ndim confirms it's 3-dimensional. The shape is described as having 1 matrix that contains 3 rows and 3 columns each.\n",
        "\n",
        "This code is a basic introduction to the concept of tensors in PyTorch, demonstrating how to create them and inspect their properties like dimensionality and shape. Understanding these properties is essential for working with data in machine learning and deep learning applications.\n",
        "\n",
        "---\n",
        "\n",
        "**Naming Conventions**\n",
        "* Scalar (dimension = 0) - lower-case $a$\n",
        "* Vector (dimension = 1) - lower-case $y$\n",
        "* Matrix (dimension = 2) - upper-case $Q$\n",
        "* Tensor (dimension ≥ 3) - upper-case $X$"
      ],
      "metadata": {
        "id": "FCG5INYwysxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar (tensor rank 0)\n",
        "scalar = torch.tensor(7) # A tensor can be constructed from a Python list or sequence using the torch.tensor() constructor\n",
        "\n",
        "print(scalar)\n",
        "print(scalar.ndim) # checks how many dimensions does scalar have\n",
        "print(scalar.shape)\n",
        "print(scalar.item()) # Get tensor back as Python int\n"
      ],
      "metadata": {
        "id": "gD0W48aJy93i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b78f5ed-d3fb-4090-9c85-dc7ea7ded1c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7)\n",
            "0\n",
            "torch.Size([])\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The .item() method is specific to tensors that have a single element. Its purpose is to extract the value of that single element as a standard Python number (int or float). It's particularly useful when you're working with tensors that result from some computations, and you want to convert the result into a Python scalar.\n",
        "\n",
        "> Attempting to use .item() on a tensor with more than one element will result in an error because it's not clear which element should be converted to a Python scalar. The method is designed to ensure that it's only used when there's exactly one element in the tensor, thereby avoiding ambiguous situations."
      ],
      "metadata": {
        "id": "0TQh-ehvd9dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector (tensor rank 1)\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector)\n",
        "print(vector.ndim) # checks how many dimension does vector have\n",
        "print(vector.shape) # outputs the shape of the vector, eg 2 by 1."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8dtOEDVW_nd",
        "outputId": "555e4f39-8c68-4524-9fb9-0eb8c9cbcc15"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7, 7])\n",
            "1\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix (tensor rank 2)\n",
        "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
        "print(MATRIX)\n",
        "print(MATRIX.ndim) # checks how many dimension does MATRIX have\n",
        "print(MATRIX.shape) # outputs the shape of the matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT1E57eiYTLz",
        "outputId": "f9ac4b3a-f80b-410a-d7f1-7ee2b61a30e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7,  8],\n",
            "        [ 9, 10]])\n",
            "2\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor (tensor rank 3+)\n",
        "TENSOR = torch.tensor([[[1, 2, 3],   #[ <-- dim=0[ <-- dim=1 [ <-- dim=2 ]]]\n",
        "                        [4, 5, 6],\n",
        "                        [6, 7, 8]]])\n",
        "print(TENSOR)\n",
        "print(TENSOR.ndim) # checks how many dimension does TENSOR have\n",
        "\n",
        "print(TENSOR.shape) # outputs the shape of the tensor\n",
        "                    # torch.Size([1, 3, 3]) means that you have 1x 3 by 3 matrix in this tensor.\n",
        "                    # torch.Size([dim=0, dim=1, dim=2])\n",
        "                    # alternatively, dim=0 contains 1 value (matrix), dim=1 contains 3 values (vector), dim=2 contains 3 scalars each.\n"
      ],
      "metadata": {
        "id": "w8NT_D3hW0NI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d52e2a4-6750-4783-ee2e-6ab9d1a8b1f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [6, 7, 8]]])\n",
            "3\n",
            "torch.Size([1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Tensors\n",
        "\n",
        "**Why random tensors?**\n",
        "\n",
        "Random tensors are important because the way many neural network learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "Workflow:\n",
        "\n",
        "> `Start with random numbers -> Look at data -> Update random numbers -> Look at data -> Update random numbers`\n",
        "\n",
        "PyTorch Docs (torch.rand()) url - https://pytorch.org/docs/stable/generated/torch.rand.html\n"
      ],
      "metadata": {
        "id": "g9bHTR3jkuDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (4, 3, 4)\n",
        "random_tensor = torch.rand(4, 3, 4) # can write \"touch.rand(size=(4, 3, 4))\" // both are acceptable\n",
        "print(random_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3OAoLvKldT6",
        "outputId": "2d9bee34-3634-44f7-dc8c-efa1b25e518f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.6498, 0.3553, 0.3500, 0.7932],\n",
            "         [0.2286, 0.6432, 0.6943, 0.8962],\n",
            "         [0.6867, 0.3233, 0.2666, 0.7687]],\n",
            "\n",
            "        [[0.0528, 0.6899, 0.0502, 0.5156],\n",
            "         [0.5681, 0.3695, 0.1795, 0.3702],\n",
            "         [0.7931, 0.4127, 0.8754, 0.1873]],\n",
            "\n",
            "        [[0.5301, 0.4967, 0.0504, 0.5414],\n",
            "         [0.8929, 0.6214, 0.8965, 0.1634],\n",
            "         [0.4742, 0.2901, 0.7088, 0.4362]],\n",
            "\n",
            "        [[0.1228, 0.3253, 0.7842, 0.9591],\n",
            "         [0.8058, 0.9020, 0.9298, 0.4675],\n",
            "         [0.1504, 0.1468, 0.6013, 0.4759]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(random_tensor.ndim) # checks how many dimension does random_tensor have\n",
        "print(random_tensor.shape) # outputs the shape of the random_tensor"
      ],
      "metadata": {
        "id": "pyNw82U6rz-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45594baf-7ebd-4b33-ed23-d8697ef4ad74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "torch.Size([4, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with simillar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # alternative is colour channel coming first, eg. size=(3, 224, 224) // both image dimension of 224x224\n",
        "print(random_image_size_tensor.ndim) # checks dimension of random_image_size_tensor\n",
        "print(random_image_size_tensor.shape) # outputs shape of random_image_size_tensor\n",
        "\n",
        "# random tensors are so valuable because neural network starts with random data -> look at data -> update the random numbers -> look at data ....."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IptIzup9r1zM",
        "outputId": "9c835229-b66b-4d33-9d5f-896843190628"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "torch.Size([224, 224, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zeros and Ones"
      ],
      "metadata": {
        "id": "VGLJ7mHWr9_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c0gcHqpClcYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all zeroes\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "print(zeros)\n",
        "print(zeros * random_tensor) # multiply zero tensor with random tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dTV48tbyNit",
        "outputId": "e3d074f2-e899-4114-b8ce-24119c49f589"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "print(ones)\n",
        "print(ones * random_tensor) # multiply zero tensor with random tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145ef0df-da24-4bc6-de5e-f070fd66b7be",
        "id": "65SLMGmxywbK"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[[0.6498, 0.3553, 0.3500, 0.7932],\n",
            "         [0.2286, 0.6432, 0.6943, 0.8962],\n",
            "         [0.6867, 0.3233, 0.2666, 0.7687]],\n",
            "\n",
            "        [[0.0528, 0.6899, 0.0502, 0.5156],\n",
            "         [0.5681, 0.3695, 0.1795, 0.3702],\n",
            "         [0.7931, 0.4127, 0.8754, 0.1873]],\n",
            "\n",
            "        [[0.5301, 0.4967, 0.0504, 0.5414],\n",
            "         [0.8929, 0.6214, 0.8965, 0.1634],\n",
            "         [0.4742, 0.2901, 0.7088, 0.4362]],\n",
            "\n",
            "        [[0.1228, 0.3253, 0.7842, 0.9591],\n",
            "         [0.8058, 0.9020, 0.9298, 0.4675],\n",
            "         [0.1504, 0.1468, 0.6013, 0.4759]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# datatype\n",
        "print(zeros.dtype)\n",
        "print(ones.dtype)\n",
        "print(random_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTjB927ny7Nc",
        "outputId": "0158890f-bb67-4d3b-afcb-4696fc7c2a23"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.float32\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Range of Tensors and Tensors-like\n",
        "\n",
        "PyTorch docs for \"torch.arange()\" - https://pytorch.org/docs/stable/generated/torch.arange.html"
      ],
      "metadata": {
        "id": "BhayhfGI03J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.range(0, 10) # depracated method, use \"torch.arange()\" instead\n",
        "one_to_ten = torch.arange(0, 10) # tensor.arange() starts at start_int, ends at end_int - 1.\n",
        "print(one_to_ten)\n",
        "one_to_k = torch.arange(start=0, end=1000, step=77)\n",
        "print(one_to_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K87hTXL-0-8v",
        "outputId": "18fa9a51-f484-43fb-f3f9-6a23f7c9b1df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors like\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten) # this will get you a tensor full of zeros, which is the same shape as the tensor input, ie \"one_to_ten\"\n",
        "print(ten_zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSKlSEhj1IE6",
        "outputId": "5f6942ed-b44a-4998-80f1-50a4c9ae91b2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Datatypes\n",
        "\n",
        "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
        "1. Tensors not right datatype (eg. happens when inconsistent dtype substitution between tensors)\n",
        "2. Tensors not right shape (eg. happens in matrix multiplication)\n",
        "3. Tensors not on the right device (eg. device=\"cpu\" vs device=\"cuda\", and device agnostic code)"
      ],
      "metadata": {
        "id": "9x-m2P_X7pU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.tensor([1.0, 2.0, 3.0], # even if dtype=None, PyTorch will then revert to default datatype\n",
        "                               dtype=None, # what datatype is the tensor (e.g float32 or float16)\n",
        "                               device=None, # what device is your tensor on\n",
        "                               requires_grad=False) # whether or not to track gradients with this tensor's operation\n",
        "print(float_32_tensor)\n",
        "print(float_32_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyiad9FQ7uEW",
        "outputId": "b7172bf9-2426-41c2-f6db-5126ef1160da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = float_32_tensor.to(dtype=torch.float16) # convert float_32_tensor to float_16_tensor // alternatively, torch.half would also work\n",
        "print(float_16_tensor)\n",
        "print(float_16_tensor.dtype) # float_16_tensor is now float 16"
      ],
      "metadata": {
        "id": "Ac4tbfNB_mKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646b6614-f30c-4a1c-e69f-e7caf957b125"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# suprisingly no error raised even though discrepancy in dtype; normal behavious, but can be an issue with large neural network,\n",
        "# but preferably don't use different' dtype\n",
        "print(float_16_tensor * float_32_tensor) # works even if multipled by torch.long or torch.int32, etc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYBr0XYkANJq",
        "outputId": "4f813e24-e069-4380-e459-2418d328feba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 4., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Information from Tensors (Tensor Attributes)\n",
        "\n",
        "1. Tensors not right datatype - to do get datatype from a tensor, can use `tensor.dtype`\n",
        "2. Tensors not right shape - to get a shape from a tensor, can use `tensor.shape`\n",
        "3. Tensors not on the right device - to get device from a tensor, can use `tensor.device`"
      ],
      "metadata": {
        "id": "QROJdy7bD0T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a test tensor\n",
        "some_tensor = torch.rand(2, 3, 4)\n",
        "print(some_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rlMn3R_GFVI",
        "outputId": "e9ca9bf1-f8e1-4c4e-d83f-ffa6e6347239"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0276, 0.2250, 0.3123, 0.6750],\n",
            "         [0.7525, 0.0452, 0.0985, 0.5865],\n",
            "         [0.9389, 0.5149, 0.1701, 0.0222]],\n",
            "\n",
            "        [[0.4056, 0.1108, 0.1038, 0.7471],\n",
            "         [0.0135, 0.2310, 0.3786, 0.1198],\n",
            "         [0.3321, 0.2377, 0.7647, 0.8875]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out details about some_tensor\n",
        "print(f\"Datatype of tensor : {some_tensor.dtype }\")\n",
        "print(f\"Shape of tensor    : {some_tensor.shape }\")  # \"some_tensor.shape\" and \"some_tensor.size()\" does the same thing (shape is attribute, .size() is founction)\n",
        "print(f\"Device of tensor   : {some_tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ8mtac0GGAq",
        "outputId": "d69302c7-d0bd-4f3d-eaa7-4a6dc91b0f99"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype of tensor : torch.float32\n",
            "Shape of tensor    : torch.Size([2, 3, 4])\n",
            "Device of tensor   : cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensors (tensor operations)\n",
        "\n",
        "Tensor Operations include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix Multiplication"
      ],
      "metadata": {
        "id": "iPHKgZUXK1KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tensor\n",
        "tensor = torch.tensor([1, 2, 3]) # initialised from Python list or array\n",
        "print(tensor)\n",
        "print(tensor + 10) # addition\n",
        "print(tensor - 10) # subtraction\n",
        "print(tensor * 10) # multiplication\n",
        "print(tensor / 10) # division"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdF00hiMLhZ-",
        "outputId": "fc2c912c-9620-48d3-866c-3a33441bf109"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([11, 12, 13])\n",
            "tensor([-9, -8, -7])\n",
            "tensor([10, 20, 30])\n",
            "tensor([0.1000, 0.2000, 0.3000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try out PyTorch built-in functions\n",
        "print(torch.add(tensor, 10)) # addition\n",
        "print(torch.sub(tensor, 10)) # subtraction\n",
        "print(torch.mul(tensor, 10)) # multiplication\n",
        "print(torch.div(tensor, 10)) # division\n",
        "\n",
        "print(torch.abs(tensor)) # absolute value\n",
        "print(torch.sqrt(tensor)) # square root\n",
        "print(torch.exp(tensor)) # exponential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSAXIojJLzyz",
        "outputId": "a7857d56-9fe7-4a80-ea6c-683700970057"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11, 12, 13])\n",
            "tensor([-9, -8, -7])\n",
            "tensor([10, 20, 30])\n",
            "tensor([0.1000, 0.2000, 0.3000])\n",
            "tensor([1, 2, 3])\n",
            "tensor([1.0000, 1.4142, 1.7321])\n",
            "tensor([ 2.7183,  7.3891, 20.0855])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "Two main ways of performing multiplication in neural networks and deep learning are:\n",
        "1. Element-wise multiplication\n",
        "2. Matrix multiplication (dot product) [dot product and matrix multiplication is used interchangeably]\n",
        "\n",
        "URL: https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
        "\n",
        "Random Note: To multiply a matrix by another matrix, we need to do the \"dot product\" of rows and columns...\n"
      ],
      "metadata": {
        "id": "FT3gAnDZNi7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise Multiplication\n",
        "print(tensor, \"*\", tensor)\n",
        "print(f\"Equals: {tensor * tensor}\")"
      ],
      "metadata": {
        "id": "g_F480MvNiqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab48893-a6bf-43c1-b649-b0c7cbebc7b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Multiplication\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpXkhMZ4PttW",
        "outputId": "826f57f4-cb7e-446c-b42f-6593ba5e4cc6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "value=0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Bf7C3xQCWX",
        "outputId": "54b8577d-bddf-4876-daa1-5f60e51f9122"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14)\n",
            "CPU times: user 3.4 ms, sys: 0 ns, total: 3.4 ms\n",
            "Wall time: 3.29 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwZo9YICQqyc",
        "outputId": "9db3ba66-126e-4de5-8da1-6fbdfb211e0f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.39 ms, sys: 70 µs, total: 1.46 ms\n",
            "Wall time: 1.68 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Miscellaneous Notes - Image Tensor"
      ],
      "metadata": {
        "id": "eTWxoO1k0yFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Prompt:** In tensor-speak (the language used to describe tensors), the tensor would have three dimensions, one for colour_channels, height and width.\n",
        "\n",
        "<br>\n",
        "\n",
        "**GPT Answer:**\n",
        "\n",
        "The quote you've provided talks about how to describe the structure of a tensor, particularly in the context of image data, using the specific terminology or \"language\" associated with tensors.\n",
        "\n",
        "In the realm of machine learning and computer vision, images are commonly represented as tensors. A tensor, in this context, is essentially a multi-dimensional array. For an image, these dimensions correspond to different aspects of the data it contains:\n",
        "\n",
        "Color Channels: The number of channels in an image represents the depth of color information. For instance, a standard RGB (Red, Green, Blue) image has three color channels. Each channel stores intensity values for its respective color across the image. There are also grayscale images, which have just one channel, and other formats that may have more channels (like RGBA, where the A stands for Alpha or transparency).\n",
        "\n",
        "Height: This dimension represents the vertical size of the image in pixels.\n",
        "\n",
        "Width: This dimension represents the horizontal size of the image in pixels.\n",
        "\n",
        "So, when the quote mentions a tensor having \"three dimensions, one for color_channels, height, and width,\" it's describing how an image is structured in a way that's understood by tensor operations. For a color image in the RGB format, you could conceptualize it as a 3D tensor:\n",
        "\n",
        "The first dimension corresponds to the color channels (3 for RGB).\n",
        "The second dimension corresponds to the height of the image in pixels.\n",
        "The third dimension corresponds to the width of the image in pixels.\n",
        "Thus, if you have a 1080x1920 pixel RGB image, in tensor-speak, you would describe it as having dimensions of 3x1080x1920, where 3 represents the RGB channels, 1080 represents the height, and 1920 represents the width.\n",
        "\n",
        "Understanding this terminology is crucial for working with image data in machine learning frameworks like TensorFlow or PyTorch, as it affects how you process, manipulate, and train models with image data.\n",
        "\n",
        "<br>\n",
        "---\n",
        "<br>\n",
        "\n",
        "Here's an example of what a tensor array for a 10x10 image with RGBA channels might look like. Each entry in this array is a randomly generated integer between 0 and 255, representing the intensity of the Red, Green, Blue, and Alpha (transparency) channels at each pixel:\n",
        "\n",
        "---\n",
        "```\n",
        "Array shape: (4, 10, 10)\n",
        "\n",
        "array([[[203, 178,  63, 203,  19,  80,  77,  99, 226, 227], #red\n",
        "        [148,  31, 141, 150, 187, 184, 214,  10,  40,  95],\n",
        "        [ 96,  76, 213, 117,  79, 224, 174,  44,   7, 236],\n",
        "        [182,  25, 242, 120, 207, 194,  52,  38,  42, 222],\n",
        "        [105, 193, 169, 146, 221,  76, 179,  84, 109, 222],\n",
        "        [  4, 105,  73,  54, 242, 172, 238,  23,  89, 192],\n",
        "        [ 79,  26,  75, 133,  92,  10, 115, 114,  87, 227],\n",
        "        [124, 183,  36, 176, 115, 246, 151, 227,  54,   1],\n",
        "        [  8, 255, 102, 242, 116,  93,  10, 184, 184,   1],\n",
        "        [161, 118,  98, 150,  89, 208,  76,  77,  58, 136]],\n",
        "\n",
        "       [[171, 231, 224, 128, 149, 101,  72, 167,  57, 178], #green\n",
        "        [170,   3, 175, 194, 243,  77, 188,  97, 197, 206],\n",
        "        [250, 197,  22, 191, 215, 156,  73,  38, 196,  34],\n",
        "        [255, 164, 187,  28, 114, 140,  65, 162,  74, 168],\n",
        "        [212, 127, 120, 162,  86,  22, 141, 126,  81, 167],\n",
        "        [168, 201,  21, 219, 148,  70, 102, 206, 111, 214],\n",
        "        [ 23, 204, 152,  56, 164, 110, 197, 213,  28, 206],\n",
        "        [162, 149, 100, 206,  25,  88, 161,  83, 173, 177],\n",
        "        [218,  38,  76, 220,  37,  36,  11, 228,   0, 107],\n",
        "        [ 29,  94, 173, 170,  31, 207, 251,  65, 205,  95]],\n",
        "\n",
        "       [[ 17, 117, 145,  64, 124,  20, 242, 202, 159,  72], #blue\n",
        "        [214, 102, 124, 170, 191,  93,  23, 251, 249,  62],\n",
        "        [ 25, 245, 169, 116, 131,  39,  68, 147,  79,  90],\n",
        "        [111,  33,  35, 196, 197, 170,  51, 197,  62,  70],\n",
        "        [ 47,  41, 113, 166, 202,  24, 242, 246,  68, 245],\n",
        "        [174,   4,  77,  83,  42,  65, 183,  58, 113,  44],\n",
        "        [221, 117, 252, 153, 119,  45, 137, 104,  58,  57],\n",
        "        [168, 231, 210, 239,  32,  30,   9, 150,  95, 214],\n",
        "        [127, 240,  56, 200, 161, 137, 197,   6, 231,  72],\n",
        "        [  4, 109,  53,  11, 197, 217,  88,   1, 249, 254]],\n",
        "\n",
        "       [[ 23, 252, 127,   8,  58, 222, 123,   6,  14, 108], #alpha\n",
        "        [  4, 195,  26, 177,  59, 145, 199, 167, 181,  93],\n",
        "        [  4, 119, 204, 182, 108,  53, 175, 159,  83,  50],\n",
        "        [ 47, 233, 103, 198,  84, 134,  42, 145,  93, 235],\n",
        "        [ 35, 165, 152,  77, 101, 153, 242, 206, 109,   9],\n",
        "        [ 78, 210, 182, 151,  48, 209, 199,  33, 138,  95],\n",
        "        [226, 206, 106,  47,  54,  49, 178, 107, 112, 105],\n",
        "        [195,  17,  24, 144,  91,  14, 102, 123, 246, 231],\n",
        "        [253, 137,  22, 133,  19, 192, 166,  24, 145,  78],\n",
        "        [ 69, 165, 135, 255, 122, 125, 135, 160, 174,  54]]], dtype=uint8)\n",
        "```\n",
        "---\n",
        "\n",
        "This representation shows a 4-dimensional tensor where:\n",
        "\n",
        "* The first dimension corresponds to the color channels (RGBA), so there are 4 layers or slices.\n",
        "* The second and third dimensions correspond to the height and width of the image, respectively, both set to 10 pixels in this example.\n",
        "\n",
        "Each \"layer\" or slice of the tensor represents one of the RGBA channels across the entire image. The values within each layer represent the intensity of that channel for each pixel, with 0 being no intensity (or completely transparent for the alpha channel) and 255 being the maximum intensity. ​​\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VwkYilIn02Ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Jupyter notebooks, which include Google Colab notebooks, you do not always need to use the print() function to display output. This environment is designed for interactive computing, and it has a feature that automatically displays the result of the last operation in each cell.\n",
        "\n",
        "When you run a cell in a Jupyter notebook (or Google Colab, which is based on Jupyter), the following rules apply:\n",
        "\n",
        "The last line of code in a cell, when executed, will have its result displayed below the cell, even if it is not printed with the print() function. This is known as the cell's output.\n",
        "If the last line of code does not produce any output, nothing is displayed.\n",
        "If you have other lines of code in the cell whose output you wish to display, you need to explicitly use print() or another display function for those lines.\n",
        "This feature is especially useful for quick data exploration and analysis, as it allows you to see the results immediately without needing to use print() every time. However, if you want to format the output or display multiple outputs within a cell, you'll need to use print() or another suitable display function."
      ],
      "metadata": {
        "id": "Yj1fmRysZZ6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes Regarding Why you don't need to declare print() to output value in Google Colab**\n",
        "\n",
        "<br>\n",
        "\n",
        "In Jupyter notebooks, which include Google Colab notebooks, you do not always need to use the $print()$ function to display output. This environment is designed for interactive computing, and it has a feature that automatically displays the result of the last operation in each cell.\n",
        "\n",
        "When you run a cell in a Jupyter notebook (or Google Colab, which is based on Jupyter), the following rules apply:\n",
        "\n",
        "1. The last line of code in a cell, when executed, will have its result displayed below the cell, even if it is not printed with the $print()$ function. This is known as the cell's output.\n",
        "2. If the last line of code does not produce any output, nothing is displayed.\n",
        "3. If you have other lines of code in the cell whose output you wish to display, you need to explicitly use $print()$ or another display function for those lines.\n",
        "\n",
        "\n",
        "This feature is especially useful for quick data exploration and analysis, as it allows you to see the results immediately without needing to use $print()$ every time. However, if you want to format the output or display multiple outputs within a cell, you'll need to use $print()$ or another suitable display function."
      ],
      "metadata": {
        "id": "LaRNJIfGZdoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miscellaneous Notes - Dimensions"
      ],
      "metadata": {
        "id": "Y_VYrwjwt_S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Prompt**: what even is ndim in torch, as in, what is dimension of tensors even. as scalars are normally assosciated with the number line 1st dimension, however here it is assosicated with the 0th dimension. can i know why does tensorflow consider scalar as 0th, vector as 1st, matrix 2nd etc\n",
        "\n",
        "<br>\n",
        "\n",
        "**GPT Answer**:\n",
        "\n",
        "The concept of dimensionality in tensors (as used in libraries like PyTorch and TensorFlow) is rooted in the mathematical definition of dimensions in linear algebra, but it's also slightly adapted to fit programming and data structure paradigms.\n",
        "\n",
        "**Understanding Dimensions**\n",
        "\n",
        "* Dimensionality: In the context of tensors, the dimensionality (or rank) refers to the number of indices required to uniquely select each element of the tensor. This concept is directly tied to how data can be organized and represented in structured forms:\n",
        "> * A scalar can be thought of as a single number. It doesn't contain any axes (or directions), so it's considered 0-dimensional. You don't need any index to access it because it's just a single value.\n",
        "> * A vector is a 1-dimensional array. You need one index to access each element. Think of it as a line where each element can be located at a certain position along that line.\n",
        "> * A matrix is a 2-dimensional array. You need two indices to access each element (one for the row and one for the column). It can be visualized as a plane or grid where positions are defined by two coordinates.\n",
        "> * Higher-dimensional tensors (3D, 4D, etc.) require more indices to access each element and represent more complex structures (like a cube for a 3D tensor).\n",
        "\n",
        "**Why Scalars are Considered 0-Dimensional**\n",
        "\n",
        "The designation of scalars as 0-dimensional in libraries like TensorFlow and PyTorch is consistent with how dimensions are mathematically defined. Since a scalar does not require any indices to access (it's just a single value), it is considered 0-dimensional. This definition helps maintain consistency across mathematical theory and its implementation in programming:\n",
        "\n",
        "* It aligns with the mathematical concept of a dimension as the number of coordinates needed to specify a point within it.\n",
        "* It provides a basis for defining operations and transformations on tensors in a way that is consistent regardless of their rank.\n",
        "\n",
        "**Practical Implications**\n",
        "\n",
        "This conceptual framework has practical implications in programming and data processing:\n",
        "\n",
        "* Generalization: By defining a scalar as a 0-dimensional tensor, vectors as 1-dimensional, matrices as 2-dimensional, and so on, libraries can offer a unified and consistent API for tensor operations that works across tensors of any dimensionality.\n",
        "* Broadcasting and Shape Manipulation: Understanding dimensionality is crucial for operations that involve multiple tensors, especially when their shapes differ. It allows for the implementation of broadcasting rules, where tensors of different shapes are used together in operations.\n",
        "* Data Representation: This hierarchical structure (scalar < vector < matrix < tensor) provides an intuitive way to represent increasingly complex data. For instance, a 3D tensor could represent a sequence of images (2D tensors), where each image is a matrix of pixel values.\n",
        "\n",
        "In summary, the classification of scalars as 0-dimensional and so on up the hierarchy to higher-dimensional tensors is a logical extension of mathematical principles into programming constructs, allowing for more versatile and powerful data manipulation capabilities in libraries like PyTorch and TensorFlow."
      ],
      "metadata": {
        "id": "MuZGa5V3uICX"
      }
    }
  ]
}